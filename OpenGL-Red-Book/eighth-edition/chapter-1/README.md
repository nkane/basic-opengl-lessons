# Introduction to OpenGL


### What is OpenGL?
OpenGL is an application programming interface (API), it is a software library for accessing features in graphics hardware.
In OpenGL, you must construct your three-dimensional objects from a small set of geometric primitives - points, lines, 
triangles, ang patches. OpenGL was first developed at Silicon Graphics Computer Systems with Version 1.0 released July of
1994.

The following is a list of brief operations that an OpenGL application would perform to render an image:
* Specify the data for constructing shapes from OpenGL's geometric primitives.
* Execute various shaders to perform calculations on the input primitives to determine their position, color, and other rendering attributes.
* Convert the mathematical description of the input primitives into their fragments associated with locations on the screen. This process is called rasterization.
* Finally, execute a fragment shader for each of the fragments generated by rasterization, which will determine the fragment's final color and position.
* Possibly perform additional per-fragment operations such as determining if the object that the fragment was generated from is visible, or blending the fragment's color with the current color in that screen locate.

OpenGL is implemented as a client-server system, with the applications written by developers being considered the client,
and the OpenGL implementation provided by the manufacturer of your computer graphics hardware being the server.

### Your First look at an OpenGL Program
The basic structure of all OpenGL applications is usually similar to the following:
* Initialize the state associated with how objects should be rendered.
* Specify those objects to be rendered.

Before we look at some code, we are going to introduce some graphics terminology. The term "rendering", is the process
by which a copmuter creates an image from models. OpenGL is just one example of a rendering system - OpenGL is a 
rasterization-based system, but there are other methods for generating images as well, such as ray tracing; however, 
even a system that uses ray tracing may employ OpenGL to display an image, or compute information to be used in creating
an image.

Our "models", or "objects" - we will use the terms interchangably - are constructed from geometric primitives - points,
lines, and triangles - that are specified by their vertices.

Another concept that is essential to using OpenGL is shaders, which are special functions that the graphics hardware executes.
The best way to think of shaders is as little programs that are specifically compiled for your graphics processing unit - 
commonly called a graphics processing unit (GPU). OpenGL includes all the compiler tool internally to take the source code of
your shader and create the code that the GPU needs to execute. In OpenGL, there are four shader stages that you can use. The 
most common are vertex shaders, which process vertex data, and fragment shaders, which operate on the fragments generated by
the rasterizer. Both vertex and fragment shaders are required in every OpenGL program.

The final generated image consist of pixels drawn on the screen; a pixel is the smallest visible element on your display. The
pixels in your system are stored in a framebuffer, which is a chunk of memory that the graphics hardware manages, and feeds to
your display device.

### Dissecting first example
This is just a disclaimer, the source code provided in the book was not complete and difficult to get started. I have re-written
portions of the code in order to get them working with libraries that regularly used at this particular point in time; however,
in the future it would be nice to remove these libraries and write a basic platform specific code to handle all of the setup
task. 

For this example we are using statically compiled version of [glew][glew-lib] and [glfw][glfw-lib]. Personally, I am not too 
familiar with these libraries at this particular point in time, so please feel free to open pull request to correct anything
that I might be missing.

Folder structure for example-1:
```plain
- example-1
  - lib
    + glew32s.lib
    + glfw3.lib
  + eglew.h
  + glew.h
  + glfw.h
  + glfw3native.h
  + glxew.h
  + wglew.h
  + main.cpp
  + build.bat
  + triangles.frag
  + triangles.vert
```

MSVC build script (build.bat):
```batch
IF NOT EXIST .\build mkdir .\build
pushd .\build

cl -Od -MD -nologo -Zi ..\main.cpp /link -incremental:no -opt:ref /LIBPATH:..\lib glew32s.lib glfw3.lib opengl32.lib glu32.lib user32.lib gdi32.lib shell32.lib

dir

popd

copy triangles.vert .\build
copy trinagles.frag .\build
```

```C
#include <iostream>

#define GLEW_STATIC

#include "glew.h"
#include "glfw3.h"

#define BUFFER_OFFSET(a) ((void *)(a))

void init(void);
void display(void);
static const GLchar* ReadShader(const char *);

enum VAO_IDs
{
	Triangles = 0,
	NumVAOs = 1
};

enum Buffer_IDs 
{
	ArrayBuffer = 0,
	NumBuffers = 1
};

enum Attrib_IDs
{
	vPosition = 0
};

GLuint VAOs[NumVAOs];
GLuint Buffers[NumBuffers];

const GLuint NumVertices = 6;

int main(int argc, char *argv[])
{
	GLFWwindow *window;

	if (!glfwInit())
	{
		return -1;
	}

	window = glfwCreateWindow(640, 480, "Hello World", NULL, NULL);
	if (!window)
	{
		glfwTerminate();
		return -1;
	}

	glfwMakeContextCurrent(window);

	if (glewInit())
	{
		glfwTerminate();
		return -1;
	}

	init();

	while (!glfwWindowShouldClose(window))
	{
		display();
		glfwSwapBuffers(window);
		glfwPollEvents();
	}
	
	glfwTerminate();

	return 0;
}

void init(void)
{
	glGenVertexArrays(NumVAOs, VAOs);
	glBindVertexArray(VAOs[Triangles]);

	GLfloat vertices[NumVertices][2] =
	{
		// Triangle One
		{ -0.90f, -0.90f },
		{  0.85f, -0.90f }, 
		{ -0.90f,  0.85f },
		// Triangle Two
		{  0.90f, -0.80f },
		{  0.90f,  0.90f },
		{ -0.85f,  0.90f }
	};

	glGenBuffers(NumBuffers, Buffers);
	glBindBuffer(GL_ARRAY_BUFFER, Buffers[ArrayBuffer]);
	glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);

	GLuint GLProgram = glCreateProgram();

	// NOTE(nick): vertex shader
	GLuint Vertex_Shader = glCreateShader(GL_VERTEX_SHADER);
	const GLchar *source = ReadShader(".\\triangles.vert");

	glShaderSource(Vertex_Shader, 1, &source, NULL); 

	glCompileShader(Vertex_Shader);

	GLint compiled;

	glGetShaderiv(Vertex_Shader, GL_COMPILE_STATUS, &compiled);

	if (!compiled)
	{
		GLsizei len;
		glGetShaderiv(Vertex_Shader, GL_INFO_LOG_LENGTH, &len);

		GLchar *log = new GLchar[len + 1];
		glGetShaderInfoLog(Vertex_Shader, len, &len, log);

		std::cerr << log << std::endl;

		delete [] log;
	}

	glAttachShader(GLProgram, Vertex_Shader);

	// NOTE(nick): fragment shader
	GLuint Fragment_Shader = glCreateShader(GL_FRAGMENT_SHADER);
	source = ReadShader(".\\triangles.frag");

	glShaderSource(Fragment_Shader, 1, &source, NULL); 

	glCompileShader(Fragment_Shader);

	glGetShaderiv(Fragment_Shader, GL_COMPILE_STATUS, &compiled);

	if (!compiled)
	{
		GLsizei len;
		glGetShaderiv(Fragment_Shader, GL_INFO_LOG_LENGTH, &len);

		GLchar *log = new GLchar[len + 1];
		glGetShaderInfoLog(Fragment_Shader, len, &len, log);

		std::cerr << log << std::endl;

		delete [] log;
	}

	glAttachShader(GLProgram, Fragment_Shader);

	glLinkProgram(GLProgram);

	GLint linked;

	glGetProgramiv(GLProgram, GL_LINK_STATUS, &linked);

	if (!linked)
	{
	        GLsizei len;
	        glGetProgramiv(GLProgram, GL_INFO_LOG_LENGTH, &len);

	        GLchar* log = new GLchar[len + 1];
        	glGetProgramInfoLog(GLProgram, len, &len, log);

		std::cerr << log << std::endl;

        	delete [] log;
	}

	delete [] source;

	glUseProgram(GLProgram);
	
	glVertexAttribPointer(vPosition, 2, GL_FLOAT, GL_FALSE, 0, BUFFER_OFFSET(0));
	glEnableVertexAttribArray(vPosition);
}

void display(void)
{
	static const float black[] = { 0.0f, 0.0f, 0.0f, 0.0f };

	glClearBufferfv(GL_COLOR, 0, black);

	glBindVertexArray(VAOs[Triangles]);
	glDrawArrays(GL_TRIANGLES, 0, NumVertices);
}

static const GLchar* ReadShader(const char *filename)
{
	FILE *InFile;
	fopen_s(&InFile, filename, "rb");

	if (!InFile) 
	{
		std::cerr << filename << std::endl;
	}

	fseek(InFile, 0, SEEK_END);
	int len = ftell(InFile);
	fseek(InFile, 0, SEEK_SET);

	GLchar *source = new GLchar[len + 1];

	fread(source, 1, len, InFile);
	fclose(InFile);

	source[len] = 0;

	return const_cast<const GLchar *>(source);
}
```
In a nutshell, here is what the example does:

* Include the appropriate header files and declare global variables and other useful programming constructs.
* The init() function is used to set up data for use later in the program. This may be vertex information for later use when rendering primitives, or image data for use in a technique called texture mapping.
* In the init() function, we first specify the position information for the two triangles that we render. After that, we specify shaders we are going to use in our program, load the shaders into memory, and compile them on the GPU. In this case, we only use the required vertex and fragment shaders. After each shader is compiled, it is attached to a GLProgram; additionally, after the needed shaders have been compiled and attached the GLProgram needs to be linked and then "used".
* The display() function is what does the rendering. That is, it calls the OpenGL functions that request something to be rendered. Almost all the display() function will do the same three steps as in our sample:
  1. Clear the window by calling glClear().
  2. Issue the OpenGL calls required to render your object.
  3. Request that the image is presented to the screen.
* Finally, the main() function does the heavy lifting of creating a window, calling the init() function, and finally entering into the event loop.

### OpenGL Syntax
All the functions in the OpenGL library begin with the letters "gl", immediately followed by one or more capitalized words to name the function (glBindVertexArray() function, for example).
All functions in OpenGL are like that; additionally, you will notice functions that beging with "glfw" that are related to the library [glfw][glfw-lib] and functions that begin with "glew"
that are related to the library [glew][glew-lib]. Similar to OpenGL's function-naming convention, constants like "GL_COLOR_BUFFER_BIT", which you saw in the function display(), are defined
for the OpenGL library. All constant tokens begin with "GL_", and use underscores to separate words. Their definitions are merely #defines found in the OpenGL header files: "glcorearb.h" and
"glext.h".

To aid in moving OpenGL applications between operating systems, OpenGL also defines various types of data for its functions, such as GLfloat, which is the floating-point value type we used to
declare vertices in the example. OpenGL defines typedefs for all of the data types accepted by its functions; additionally, since OpenGL is a "C"-language library, it does not have function
overloading to deal with the different types of data - instead it uses a function-naming convention to organize the multitude of functions that result from that situtation. For example,
we will ecounter a function named glUniform*() in Chapter 2, "Shader Fundamentals", which comes in numerous forms, such as glUniform2f() and glUniform3fv(). The suffixes at the end of the "core"
part of the function name provide information about the arguments passed to the function. For example, the "2" in glUniform2f() represents that two data values will be passed into the function.
Also, note the "f" following the "2" - this indicates that those two parameters are of type GLfloat. Finally, versions of the functions name end with a "v", which is short for "vector", meaning
that the two floating-point values (int the case of glUniform2fv()) are passed as a one-dimensional array GLfloats, instead of two separate parameters.

| Suffix        | Data Type               | Typical Corresponding C-Language Type  | OpenGL Type Definition 	|
| ------------- | ----------------------- | -------------------------------------- | -------------------------- |
| b 		| 8-bit integer	          | signed char 			   | GLbyte		    	|
| s 		| 16-bit integer          | signed short 		           | GLshort		    	|
| i 		| 32-bit integer          | int	 			       	   | GLint, GLsizei         	|
| f 		| 32-bit float-point      | float	 			   | GLfloat, GLclampf	    	|
| d 		| 64-bit float-point      | double	 			   | GLdouble, GLclampd	    	|
| ub 		| 8-bit unsigned integer  | unsigned char 	 		   | GLubyte		    	|
| us 		| 16-bit unsigned integer | unsigned short 	 		   | GLushort		        |
| ui 		| 32-bit unsigned integer | unsigned int 	 		   | GLuint, GLenum, GLbitfield |

### OpenGL's Rendering Pipeline
OpenGL implements a "rendering pipeline", which is a sequence of processing stages for converting the data your application provides to OpenGL into a final rendered image. Below is a overview
of how OpenGL pipeline associated with Version 4.3 works:

```plain
	Vertex Data -> Vertex Shader -> Tesselation Control Shader -> Tesselation Evalutation Shader ---\
	/-----------------------------------------------------------------------------------------------|
	V
	Geometry Shader -> Primitive Setup -> Clipping -> Rasterization -> Fragment Shader -> "Output Image :)"
```

OpenGL begins with the geometric data you provide (vertices and geometric primitives) and first processes it through a sequence of shader stages: vertex shading, tessellation shading (which
itself uses two shaders), and finally geometry shading, before it's passed to the rasterizer. The rasterizer will generate fragments for any primitive that's inside of the clipping region,
and execute a fragment shader for each of the generated fragments; additionally, you have complete control of which shaders stages are used, and what each of them do. Not all stages are
required - only the vertex and fragment shaders must be included. Tessellation and geometry shaders are optional.

### Preparing to Send Data to OpenGL
OpenGL requires that all data be stored in buffer objects, which are just chunks of memory managed by the OpenGL server. Populating these buffers with data can occur in numerous ways, but
one of the most common is using the glBufferData() command.

### Sending data to OpenGL
After we have initialized our buffers, we can request geometric primitives be rendered by calling one of OpenGL's drawing commands, such as glDrawArrays(). Drawing in OpenGL usually means
transferring vertex data to the OpenGL server.

### Vertex Shading
For each vertex that is issued by a drawing command, a vertex shader will be called to process the data associated with that vertex. Depending on whether any other pre-rasterization shaders
are active, vertex shaders may be simple, perhaps just copying data to pass it through this shading stage, generally considered a "pass-through-shader" to a complex shader that is performing
many computations to potentially compute the vertex's screen position (usually using transformation matrices), determining the vertex's color using lighting computations or any multitude of
other techniques. A typical application of any complexity will have multiple vertex shaders, but only one can be active at any one time.

### Tessellation Shading
After the vertex shader has processed each vertex's associated data, the tessellation shader stage will continue processing that data, if it has been activated. Tessellation uses patchs to
describe an object's shape, and allows relatively simple collections of patch geometry to be tessellated to increase the number of geometric primitives providing better-looking models. The
tessellation shading stage can potentially use two shaders to manipulate the patch data and generate the final shape.

### Geometry Shading
Geometry shading, allows additional processing of individual geometric primitives, including creating new ones, before rasterization. This shading stage is also optional but powerful.

### Primitive Assembly
The previous shading stages all operate on vertices, with the information about how those vertices are organized into geometric primitives being acrried along internal to OpenGL. The
primitive assembly stage organizes the vertices into their associated geometric primitives in preparation for clipping and rasterization.

### Clipping
Occasionally, vertices will be outside of the viewport - the region of the window where you are permitted to draw - and case the primitive associated with that vertex to be modified. 
Meaning that none of its pixels are outside of the viewport. This operation is called clipping and it is handled automatically by OpenGL.

### Rasterization
After clipping is complete, the updated primitives are sent to the rasterizer for fragment generation. Consider a fragment a "candidate pixel", in that pixels have a home in the framebuffer,
while a fragment still cann be rejected and never update its associated pixel location. Processing of fragments occurs in the next two stages, fragment shading and per-fragment operations.

### Fragment Shading
THe final stage where the programmer has programmable control over the color of a screen location is during the fragment shading. In this shader stage, you use a shader to determine the fragment's
final color (although the next stage, per-fragment operations can modify the color one last time), and potentially its depth value. Fragment shaders are powerful as they often emply texture mapping
to augment the colors provided by the vertex processing stages. A fragment shader may also terminate processing a fragment if it determines that fragment should not be drawn; this process is called
"fragment discard".

A helpful way of thinking about the difference between shaders that deal with vertices and fragment shaders is: vertex shading (including tesselation and geometry shading) determine where on the
screen a primitive is, while fragment shading uses that information to determine what color that fragment will be.

### Pre-Fragment Operations
Additional fragment processing, outside of what you can currently do in a fragment shader is the final processing of individual fragments. During this stage a fragment's visibility is determined
using "depth testing" (also commonly known as "z-buffering") and "stencil testing". If a fragment successfully makes it through all of the enabled tests, it may be written directly to the framebuffer,
updating the color (and possibly depth value) of its pixel, or if blending is enabled, the fragment's color will be combinded with the pixel's current color to generate a new color that is written
into the framebuffer.

Gernally, pixel data comes from an image file, although it may also be created by rendering using OpenGL. Pixel data is usually stored in "texture map's" for use with texture mapping, which allows
any texture stage to look up data values from one or more texture maps.

### Our First Program: A Detailed Discussion
Starting at the beginning, of how our program would execute - we first look at what is going on in the main() function:

#### Main
The first line declares a variable of type GFLWwindow, this type is declared in the [glfw][glfw-lib] library. The next line is a function call glfwInit() that sets up platform specific window
contexting for the [glfw][glfw-lib] library. The following function call glfwCreateWindow() creates a platform independent window context and returns the GLFWwindow type fully populated. Next,
the function glfwMakeContextCurrent makes the OpenGL context of the specific window current on the calling thread - a context can only be made current on a single thread at a time and each
thread can have only a single current context at a time. If the window does not register successfully, a call to glfwTerminate() is made - this function destroys all remaining windows and
cursors, restores any modified gamma ramps and frees any other allocated resources. 

Continuing on, the call to glewInt() initializes another library that this source code is using: [glew][glew-lib](OpenGL Extension Wrangler). GLEW's job is to simplify dealing with accessing
functions and other interesting programming phenomena introduced by the various operating systems with OpenGL. The next function call is our own init() function that we will cover momentarliy.
A function call to glfwWindowShouldClose() passing in the declared GLFWwindow pointer variable - this is the event loop that will continue until a quit message has been posted to the application.
Within the event loop, we are calling our declared function display() that we will cover as well. The next function call is to glfwSwapBuffers() - this function swaps the front and back buffers of
the specific window when rendering with OpenGL. If the swap interval is greater than zero, the GPU driver waits the specific number of screen updates before swapping buffers. After the buffers have
been swaped, the next call is glfwPollEvents() - this function processes only those events that are already in the event queue and then returns immediately. Processing events will cause the window
and input callbacks acssociated with those events to be called.

```C
int main(int argc, char *argv[])
{
	GLFWwindow *window;

	if (!glfwInit())
	{
		return -1;
	}

	window = glfwCreateWindow(640, 480, "Hello World", NULL, NULL);
	if (!window)
	{
		glfwTerminate();
		return -1;
	}

	glfwMakeContextCurrent(window);

	if (glewInit())
	{
		glfwTerminate();
		return -1;
	}

	init();

	while (!glfwWindowShouldClose(window))
	{
		display();
		glfwSwapBuffers(window);
		glfwPollEvents();
	}
	
	glfwTerminate();

	return 0;
}
```

#### OpenGL Initialization
This portion is going to cover the init() function that we have defined in our program - this portion of the program vastly differs from the books example.
The first function glGenVertexArrays(GLsizei n, GLunint *arrays), allocates "n" number of vertex array object names for uses throughout this program. In 
this program's case, NumVAOs is specified in the global variable section of the code - the glGenVertexArrays() returns the number of names to the caller's
provided array, in this case VAOs (type - GLuint []). On another note, we will see numerous OpenGL commands of the form "glGen*", for allocating names to
the various types of OpenGL objects. 

A "name" is similiar to a pointer-type variable in C, in that until you allocate some memory and have the name reference it, the "name" is not much help.
In OpenGL, the same holds true, and our allocation scheme is called "binding an object" - this is done by a collection of functions in OpenGL that have
the form "glBind". For this exmaple program, we create and bind a "vertex-array object" using glBindVertexArray(GLuint array). The function glBindVertextArray()
does three things - when using the value array that is other than zero and was returned from our previous call glGenVertexArrays(), a new "vertex-array object"
is created and assigned that name. When binding to a previously created "vertex-array object", that vertex array object becomes active, which additionally affects
the vertex array state stored in the object. When binding to an array value of zero, OpenGL stops using application-allocated "vertex-array objects" and returns
to the default state for vertex arrays.

In this example, after a "vertex-array object" is generated - it is bound (using object binding) with the call to glBindVertexArray(). Object binding is a common
operation in OpenGL. When binding to an object for the first time (e.g., the first time "glBind*()" is called for a particular object name), OpenGL will internally
allocate the memory  it needs and make that object current, which means that any operations relevant to the bound object, like the "vertex-array object", will affect
its state from that point on in the program's execution. After the first call to "glBind*()" function, the newly created object will be initialized to its default
state and typically requires additional initialization to make it useful. Think of binding an object like setting a track switch in a railroad yard - once the track
switch has been set, all trains go down that set of tracks; however, when the switch is set to another track - all trains will then travel that new track. In general,
it is the same for OpenGL objects. OpenGL objects need to be bound to an object in two situations:

* Initially when an object has been created and initialized with data that is will hold.
* Everytime an object that has been created and initialized needs to be used and is not currently bound.

This latter situation listed will be described in detail when we get to the display function() where the function glBindVertexArray() is called the second time in the
program; additionally, to provided completeness that is not provided in the example code the function glDeleteVertexArrays(GLsizei n, GLuint *arrays) is called once
completed with a "vertex-array object" - the function glDeleteVertexArrays() deletes the n "vertex-array objects" specified in arrays, enabling the names for reuse as
vertex arrays later. If a bound vertex array is deleted, the bindings for that vertex become zero (as if you had called glBindBuffer() with a value of zero) and the
default vertex array becomes the current one. Unused names in arrays are released, but no changes to the current vertex array state are made; additonally, it can be
determined if a name has been previously reserved as a "vertex-array object" by calling gllsVertexArray(GLuint array) - the function gllsVertexArray() returns GL_TRUE
if the array is the name of a "vertex-array object" that was previously generated with glGenVertexArrays(), but has not been subsequently deleted, or the function
returns GL_FALSE if the array is zero or nonzero value that is not the of a "vertex-array object". There simliar functions of the form glDelete* and glls* for all
different tpyes of objects in OpenGL.

```C
// NOTE: the follow variables are globally defined in the example program ...
// VAO = Vertex-Array Object(s)
// VBO = Vertex-Buffer Object(s)

enum VAO_IDs
{
	Triangles = 0,
	NumVAOs = 1,
};

enum Buffer_IDs
{
	ArrayBuffer = 0,
	NumBuffers = 1,
};

enum Attrib_IDs
{
	vPosition = 0,
};

GLuint VAOs[NumVAOs];
GLuint Buffers[NumBuffers];

const GLuint NumVertices = 6;

void init(void)
{
	glGenVertexArrays(NumVAOs, VAOs);
	glBindVertexArray(VAOs[Triangles]);

	GLfloat vertices[NumVertices][2] =
	{
		// Triangle One
		{ -0.90f, -0.90f },
		{  0.85f, -0.90f }, 
		{ -0.90f,  0.85f },
		// Triangle Two
		{  0.90f, -0.80f },
		{  0.90f,  0.90f },
		{ -0.85f,  0.90f }
	};

	glGenBuffers(NumBuffers, Buffers);
	glBindBuffer(GL_ARRAY_BUFFER, Buffers[ArrayBuffer]);
	glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);

	GLuint GLProgram = glCreateProgram();

	// NOTE(nick): vertex shader
	GLuint Vertex_Shader = glCreateShader(GL_VERTEX_SHADER);
	const GLchar *source = ReadShader(".\\triangles.vert");

	glShaderSource(Vertex_Shader, 1, &source, NULL); 

	glCompileShader(Vertex_Shader);

	GLint compiled;

	glGetShaderiv(Vertex_Shader, GL_COMPILE_STATUS, &compiled);

	if (!compiled)
	{
		GLsizei len;
		glGetShaderiv(Vertex_Shader, GL_INFO_LOG_LENGTH, &len);

		GLchar *log = new GLchar[len + 1];
		glGetShaderInfoLog(Vertex_Shader, len, &len, log);

		std::cerr << log << std::endl;

		delete [] log;
	}

	glAttachShader(GLProgram, Vertex_Shader);

	// NOTE(nick): fragment shader
	GLuint Fragment_Shader = glCreateShader(GL_FRAGMENT_SHADER);
	source = ReadShader(".\\triangles.frag");

	glShaderSource(Fragment_Shader, 1, &source, NULL); 

	glCompileShader(Fragment_Shader);

	glGetShaderiv(Fragment_Shader, GL_COMPILE_STATUS, &compiled);

	if (!compiled)
	{
		GLsizei len;
		glGetShaderiv(Fragment_Shader, GL_INFO_LOG_LENGTH, &len);

		GLchar *log = new GLchar[len + 1];
		glGetShaderInfoLog(Fragment_Shader, len, &len, log);

		std::cerr << log << std::endl;

		delete [] log;
	}

	glAttachShader(GLProgram, Fragment_Shader);

	glLinkProgram(GLProgram);

	GLint linked;

	glGetProgramiv(GLProgram, GL_LINK_STATUS, &linked);

	if (!linked)
	{
	        GLsizei len;
	        glGetProgramiv(GLProgram, GL_INFO_LOG_LENGTH, &len);

	        GLchar* log = new GLchar[len + 1];
        	glGetProgramInfoLog(GLProgram, len, &len, log);

		std::cerr << log << std::endl;

        	delete [] log;
	}

	delete [] source;

	glUseProgram(GLProgram);
	
	glVertexAttribPointer(vPosition, 2, GL_FLOAT, GL_FALSE, 0, BUFFER_OFFSET(0));
	glEnableVertexAttribArray(vPosition);
}
```

#### Allocating Vertex-Buffer Objects
A vertex-array object holds various data related to a collection of vertices. The data is tored in a buffer object and managed by the currently bound vertex-array object.
While there is only a single type of vertex-array object, there are many types of objects, but not all of them specifically deal with vertex data. As mentioned previously,
a buffer object is memory that the OpenGL server allocates and owns, and almost all data passed into OpenGL is done by storing the data in a buffer object.

The code sequence of initializing a vertex-buffer object is similiar in flow to that of creating a vertex-array object, with an added step to actually populate the buffer
with data. The fist step, names need to be created for the vertex-buffer objects. The function glGenBuffers(GLsizei n, GLuint *buffers) is used to to return "n" currently
unused names for buffer objects in the array buffers; additionally, the names returned in buffers do not have to be a contiguous set of integers. In the example code,
NumVBO (vertex buffer objects) is allocated into the array "buffers". 

Once names have been allocated for the buffer, they can be brough into existence by calling the glBindBuffer(GLenum target, GLuint buffer) function. Since there are many
different types of buffer objects in OpenGL, when a buffer is bound the type needs to be specified - in this example GL_ARRAY_BUFFER is being used. As with other objects,
buffer objects can be deleted with glDeleteBuffers(GLsizei n, const GLuint *buffers). Querying if an integer value is a buffer-object name with gllsBuffer(GLuint buffer)
is possible. 

#### Loading Data into a Buffer Object
After initializing the vertex-buffer object, the vertex data needs to be tranferred from our objects into the buffer object. This is done by the glBufferData() function -
this function allocates storage for holding the vertex data and copying the data from arrays in the application to the OpenGL server's memory. The function's current 
contract is the following - glBufferData(GLenum target, GLsizeiptr size, const GLvoid *data, GLenum usage).

The vertex data is tored in the array vertices. Typically, these values might be read in from a file containing a model or generate the values algorithmically. Since the
data is vertex-attribute data, the buffer needs specified as a GL_ARRAY_BUFFER in the call to glBufferData() as the first parameter, the next parameter is the size of
memory to be allocated (in bytes) by computing the sizeof(vertices) will handle that, and last specify hwo the data will be used by OpenGL. Since the data will be used
for drawing geometry, and will not change for the life of the program GL_STATIC_DRAW is a decent choice.

If you take a look at the values in the vertice array, you will notice that they are all in the range -1 to 1 in both X and Y fields. In reality, OpenGL only knows how to
draw geometric primitives into coordinate space. In fact, the range coordinates are known as normalized-device coordinates (NDCs). 

#### Initializing Our Vertex and Fragment Shaders
Every OpenGL program that wants to use OpenGL Version 3.1 or greater must provide at least two shaders:

* A vertex shader
* A fragment shader

In this code example, we accomplish that by using our using the glCreateProgram(void) function - this function creates an empty program object, a program object is an object
to which a shader object(s) can be attached. Next, we create a vertex shader by calling the glCreateShader(GLenum shaderType) function - this function creates an empty shader
object and returns a non-zero value by which it can be referened. A shader object is used to maintain the source code strings taht define a shader (for vertex shaders, 
GL_VERTEX_SHADER is used). Following the creation of the vertex shader, the source code for the vertex shader needs to be loaded into memory with the help of a function 
defined and implemented in the source code called ReadShader(char *). Once completed reading in the vertex shader source code and loading into memory, the function
glShaderSource(GLuint shader, GLsizei count, const GLchar **string, const GLint *length) is called - this function sets the source code in the shader to the source code
in the array of strings specified by the string. After the source code for the vertex shader is set / copied over to the Vertex_Shader object, the shader needs to be compiled
by calling glCompileShader(GLuint shader) - glCompileShader() compiles the source code strings that have been stored in the shader object specified by shader. Next, we need
to check that the shader compiled successfully on the GPU by creating GLint variable "compiled" and querying the GPU for the compile status - this is done by calling the 
function glGetShaderiv(GLuint shader, GLenum pname, GLint *params), the function glGetShaderiv() returns the params the value of a parameter for a specific shader object. In 
this case we are checking to see if a shader has successfully compiled, so we need to use GL_COMPILE_STATUS. Using that flag will return GL_TRUE if the last compiled operation
on the shader was successful and GL_FALSE otherwise. Finally, once the vertex shader has been compiled successfully on the GPU the glAttachShader(GLuint program, GLuint shader)
function is called in order to attach shader(s) objects specified by shader to the program object specified by program. This indicates that shader will be included in link
operations that will be performed on program.

The process for fragment shader is similiar to the above, but different enums are passed in as arguments - at this point it would be wise to review the source to get a better
perspective on how loading / compiling shaders works. Once completed attaching the fragment shader to the program, we need to attempt to link the program together with the attached
shaders by calling glLinkProgram(GLuint program) - glLinkProgram() links the program object. Once we attempt to link the program, we need to query the GPU to see if the program
successfully linked creating a new GLint variable linked and passing it in to the function glGetProgramiv() with the flag option GL_LINK_STATUS. Once the program has been successfully
compiled and linked, the function glUseProgram(GLuint program) can be called - glUseProgram() specifies the handle of the program object whose executables are to be used as part of
current rendering state.

Vertex Shader Example:
```GLSL
#version 430 core

layout (location = 0) in vec4 vPosition;

void
main()
{
	gl_Position = vPosition;
}
```

Above is the vertex shader used in the example program, this vertex shader is example of a "pass-through shader" - meaning it only copies input data to output data. The first line is
"#version 430 core", this specifies what version of OpenGL Shading Language that is to be used. The "430" indicates that the version of GLSL associated with OpenGL Version 4.3. Next,
a shader variable is allocated. Shader variables are a shader's conneciton to the outside world - meaning that a shader does not know where data comes from, but it sees its input
variables populated with data everytime it executes. It is the programmers responsiblity to connect the shader plumbing, so that way data can flow into and between the various OpenGL
shader stages. The one variable declared is vPosition, it is considered input, because of the "in" keyword. Typically, it is easier to tell what is going on with variable declaration
line by reading it from right to left:

* vPosition is the name of the variable - the v prefix stands for vertex.
* vec4 is a four-component vector of floating-point values; additionally, the data for each vertex only defines two coordinates instead of four in the example program - where do the other two coordinates come from? OpenGL will automatically fill in any missing coordinates with default values. The vec4 default value is a vec4(0, 0, 0, 1).
* in is a keyword taht describes which direction the data flows into the shader. If you are wondering if there might be an out, that would be correct.
* lastly, the layout(location = 0) part is called a layout qualifier, it provides meta-data for our variable declaration. There are many options that can be set with a layout qualifier.

The core of the vertex shader is defined in the main() function. Every shader in OpenGL, regardless of what type / stage the shader is used for it will have a main() funciton. For our
example's vertex shader, all it does is copy the input vertex position to the special vertex-shader ouptut gl_Position. 

Fragment Shader Example:
```GLSL
#version 430

out vec4 fColor;

void
main()
{
	fColor = vec4(0.0, 0.0, 1.0, 1.0);
}

```
The fragment shader should look similar in format to the vertex shader; however, the highlights of the example's fragment shader are the following:
* The variable declared fColor is an output value that is the fragments color.
* Assigning the fragment's color. In this case, each fragment is assigned this vector of four values. In OpenGL, colors are represented in what is called RGB color space, with each color
component ("R" for red, "G" for green, and "B" for blue) ranging 0 - 1; additionally, OpenGL actually uses RGBA (A for Alpha) color space. Alpha, is a measure of translucency. Fragment
shaders are immensely powerful, and there will be many techniques that we can do with them.


The final two functions in the inti() function deal specifically with associating variables in a vertex shader with data that has been stored in a buffer object. This is what was previously
referred to as the shader plumbing, in that a conduit between the application and a shader(s) needs to be setup. To associate data going into the vertex shader, which is the entrance all vertex
data take to get processed by OpenGL, the shader's "in" variables need to be connected to a vertex-attribute array - this is accomplished by calling the function
glVertexAttribePointer(GLuint index, GLint size, GLenum type, GLboolean normalized, GLsizei stride, const GLvoid *pointer). The glVertexAttribPointer() function specifies where the data values
for the index (shader attribute location) can be accessed, pointer is the offest from the start of the buffer object (assuming zero-based addressing) in basic-machine units (i.e., bytes) for
the first set of values in the array, size represents the number of components to be updated per vertex, and ca be either 1, 2, 3, 4, or GL_BGRA, type specifies the data type of each element
in the array, normalized indicates that the vertex data should be normalized, stride is the byte offset between consecutive elements in the array. 

At this point, the last remaining task is to enable the vertex-attribute array - this is accomplished by calling glEnableVertexAttribArray(GLuint index) and passing the index of the attribute
array pointer initialized by calling glVertexAttribPointer() function.

#### First OpenGL Rendering
Once all the above is setup and data is initialized, rendering (for the moment) is quiet simple. While the display() function is only a few lines long it is a sequence of operations that is
virtually the same in all OpenGL applications:

```C
void display(void)
{
	static const float black[] = { 0.0f, 0.0f, 0.0f, 0.0f };
	
	glClearBufferfv(GL_COLOR, O, black);

	glBindVertexArray(VAO[Triangles]);
	glDrawArrays(GL_TRIANGES, 0, NumVertices);
}
``` 

First, the function begins by clearing the framebuffer another function that could be used is glClear(GLbitfield mask) - this function clears the specified buffers to their current clearing values. The mask argument is a
bitwise logical OR combination of values; however, instead we use glClearBufferfv(). The next calls select the collection of vertices that are going to be drawn and request tahy they be rendered - the next function cal
is glBindVertexArray() to select the vertex array that is going to be used as vertex data. Once that is complete, the function glDrawArrays(GLenum mode, GLint first, GLsizei count) is called - this function constructs
a sequence of geometric primitives using the elements from the currently bound vertex array starting at first and ending at first + count - 1, mode specifies what kinds of primitives are constructed. The glFlush() function
forces previously issues OpenGL commands to begin execution, thus guaranteeing that they completed in finite time.


#### Advanced
In order to accurately measure how long a process takes - the process may be an the time to render an object, draw a full scene, or any other operations that OpenGL might do, we need to know when OpenGL is completed with
whatever operations that are being measured. A useful function while developing is, glFinish(void) - the glFinish() function forces completion of all pending OpenGL commands and waits for their completion. Another two
functions that are useful, void glEnable(GLenum) and void glDisable(GLenum) - glEnable() turns on capabilities and glDisable() turns off capabilities.

[glew-lib]: 	http://glew.sourceforge.net/
[glfw-lib]:	http://www.glfw.org/
